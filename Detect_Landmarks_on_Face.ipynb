{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c75BAnSh10di",
        "outputId": "13fb8692-9af3-4bca-e011-4e418cf3ef98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auaBQ-QPsS7K"
      },
      "source": [
        "Import library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNl66vGsrr65"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from torchsummary import summary\n",
        "import time\n",
        "import cv2\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import imutils\n",
        "import matplotlib.image as mpimg\n",
        "from collections import OrderedDict\n",
        "from skimage import io, transform\n",
        "from math import *\n",
        "import xml.etree.ElementTree as ET\n",
        "from IPython.display import display\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torchsummary import summary\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms.functional as TF\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import Dataset, ConcatDataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import lr_scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuejihrqxJ39"
      },
      "source": [
        "Create Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fORsGe-cxjEb"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "if not os.path.exists('/content/ibug_300W_large_face_landmark_dataset'):\n",
        "    !wget http://dlib.net/files/data/ibug_300W_large_face_landmark_dataset.tar.gz\n",
        "    !tar -xvzf 'ibug_300W_large_face_landmark_dataset.tar.gz'\n",
        "    !rm -r 'ibug_300W_large_face_landmark_dataset.tar.gz'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwbQUUdHxEjs"
      },
      "outputs": [],
      "source": [
        "class Transforms():\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def rotate(self, image, landmarks, angle):\n",
        "        angle = random.uniform(-angle, +angle)\n",
        "\n",
        "        transformation_matrix = torch.tensor([\n",
        "            [+cos(radians(angle)), -sin(radians(angle))],\n",
        "            [+sin(radians(angle)), +cos(radians(angle))]\n",
        "        ])\n",
        "\n",
        "        image = imutils.rotate(np.array(image), angle)\n",
        "\n",
        "        landmarks = landmarks - 0.5\n",
        "        new_landmarks = np.matmul(landmarks, transformation_matrix)\n",
        "        new_landmarks = new_landmarks + 0.5\n",
        "        return Image.fromarray(image), new_landmarks\n",
        "\n",
        "    def resize(self, image, landmarks, img_size):\n",
        "        image = TF.resize(image, img_size)\n",
        "        return image, landmarks\n",
        "\n",
        "    def crop_face(self, image, landmarks, crops):\n",
        "        left = int(crops['left'])\n",
        "        top = int(crops['top'])\n",
        "        width = int(crops['width'])\n",
        "        height = int(crops['height'])\n",
        "\n",
        "        image = TF.crop(image, top, left, height, width)\n",
        "\n",
        "        img_shape = np.array(image).shape\n",
        "        landmarks = torch.tensor(landmarks) - torch.tensor([[left, top]])\n",
        "        landmarks = landmarks / torch.tensor([img_shape[1], img_shape[0]])\n",
        "        return image, landmarks\n",
        "\n",
        "    def __call__(self, image, landmarks, crops):\n",
        "        image = Image.fromarray(image)\n",
        "        image, landmarks = self.crop_face(image, landmarks, crops)\n",
        "        image, landmarks = self.resize(image, landmarks, (224, 224))\n",
        "        image, landmarks = self.rotate(image, landmarks, angle=10)\n",
        "\n",
        "        image = TF.to_tensor(image)\n",
        "        image = TF.normalize(image, [0.5], [0.5])\n",
        "        return image, landmarks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTVeXCLhxOeu"
      },
      "outputs": [],
      "source": [
        "class FaceLandmarksDataset(Dataset):\n",
        "\n",
        "    def __init__(self, transform=None):\n",
        "\n",
        "        tree = ET.parse('/content/ibug_300W_large_face_landmark_dataset/labels_ibug_300W_train.xml')\n",
        "        root = tree.getroot()\n",
        "\n",
        "        self.image_filenames = []\n",
        "        self.landmarks = []\n",
        "        self.crops = []\n",
        "        self.transform = transform\n",
        "        self.root_dir = 'ibug_300W_large_face_landmark_dataset'\n",
        "\n",
        "        for filename in root[2]:\n",
        "            self.image_filenames.append(os.path.join(self.root_dir, filename.attrib['file']))\n",
        "\n",
        "            self.crops.append(filename[0].attrib)\n",
        "\n",
        "            landmark = []\n",
        "            for num in range(68):\n",
        "                x_coordinate = int(filename[0][num].attrib['x'])\n",
        "                y_coordinate = int(filename[0][num].attrib['y'])\n",
        "                landmark.append([x_coordinate, y_coordinate])\n",
        "            self.landmarks.append(landmark)\n",
        "\n",
        "        self.landmarks = np.array(self.landmarks).astype('float32')\n",
        "\n",
        "        assert len(self.image_filenames) == len(self.landmarks)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_filenames)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = cv2.imread(self.image_filenames[index])\n",
        "        landmarks = self.landmarks[index]\n",
        "\n",
        "        if self.transform:\n",
        "            image, landmarks = self.transform(image, landmarks, self.crops[index])\n",
        "\n",
        "        landmarks = landmarks - 0.5\n",
        "\n",
        "        return image, landmarks\n",
        "dataset = FaceLandmarksDataset(Transforms())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbRIr-BJymmF"
      },
      "source": [
        "Split dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBw8bMQpyoAW",
        "outputId": "3eb27f19-d565-4cfc-933d-90ade6708066"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of Train set is 6000\n",
            "The length of Valid set is 666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "# split the dataset into validation and test sets\n",
        "len_valid_set = int(0.1*len(dataset))\n",
        "len_train_set = len(dataset) - len_valid_set\n",
        "\n",
        "print(\"The length of Train set is {}\".format(len_train_set))\n",
        "print(\"The length of Valid set is {}\".format(len_valid_set))\n",
        "\n",
        "train_dataset , valid_dataset,  = torch.utils.data.random_split(dataset , [len_train_set, len_valid_set])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=8, shuffle=True, num_workers=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qpow_AeFyrDG"
      },
      "source": [
        "Helper function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23XZX71Dysro"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "def print_overwrite(step, total_step, loss, operation):\n",
        "    sys.stdout.write('\\r')\n",
        "    if operation == 'train':\n",
        "        sys.stdout.write(\"Train Steps: %d/%d  Loss: %.8f \" % (step, total_step, loss))\n",
        "    else:\n",
        "        sys.stdout.write(\"Valid Steps: %d/%d  Loss: %.8f \" % (step, total_step, loss))\n",
        "\n",
        "    sys.stdout.flush()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZWrQ7B0w_Ky"
      },
      "source": [
        "Define the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CaNZFZtpvK0h"
      },
      "outputs": [],
      "source": [
        "class ResNet18Finetune(nn.Module):\n",
        "  def __init__(self, output_shape=[68, 2]):\n",
        "    super().__init__()\n",
        "    self.output_shape = output_shape\n",
        "    backbone = models.resnet18(pretrained=True)\n",
        "    layers = list(backbone.children())\n",
        "    self.feature_extractor = nn.Sequential(*layers[:-1]) #Cut the fc layer in the last\n",
        "\n",
        "    #freeze all the layers in feature extractor\n",
        "    for parameter in self.feature_extractor.parameters():\n",
        "      parameter.requires_grad = False\n",
        "\n",
        "    #unfreeze some last layers:\n",
        "    for param in self.feature_extractor[-2][1].parameters():\n",
        "      param.requires_grad = True\n",
        "\n",
        "    #get the input feature in the last layer\n",
        "    num_filters = backbone.fc.in_features\n",
        "\n",
        "    #create the fully connected layers in the last layer\n",
        "    self.output_layer = nn.Linear(num_filters, self.output_shape[0]*self.output_shape[1])\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.feature_extractor(x)\n",
        "\n",
        "    #Flatten x\n",
        "    x = x.view(x.size(0), -1)\n",
        "\n",
        "    x = self.output_layer(x)\n",
        "    x = x.view(x.size(0), self.output_shape[0], self.output_shape[1])\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Av6egB0-yN_I"
      },
      "source": [
        "Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdVujVLFyPJv",
        "outputId": "c78d3c94-75a4-46d7-9fa5-e7f482ff4a72"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 142MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1 - Train Loss: 0.188101, Valid Loss: 0.124090, Elapsed time: 201s\n",
            "New minimum validation loss of 0.124090 at epoch 1. Model saved at /content/drive/MyDrive/face_landmark_234241.pt\n",
            "\n",
            "Epoch: 2 - Train Loss: 0.104344, Valid Loss: 0.095668, Elapsed time: 197s\n",
            "New minimum validation loss of 0.095668 at epoch 2. Model saved at /content/drive/MyDrive/face_landmark_234241.pt\n",
            "\n",
            "Epoch: 3 - Train Loss: 0.085914, Valid Loss: 0.081629, Elapsed time: 198s\n",
            "New minimum validation loss of 0.081629 at epoch 3. Model saved at /content/drive/MyDrive/face_landmark_234241.pt\n",
            "\n",
            "Epoch: 4 - Train Loss: 0.077808, Valid Loss: 0.083494, Elapsed time: 198s\n",
            "\n",
            "Epoch: 5 - Train Loss: 0.072980, Valid Loss: 0.072830, Elapsed time: 198s\n",
            "New minimum validation loss of 0.072830 at epoch 5. Model saved at /content/drive/MyDrive/face_landmark_234241.pt\n",
            "\n",
            "Epoch: 6 - Train Loss: 0.069114, Valid Loss: 0.068305, Elapsed time: 196s\n",
            "New minimum validation loss of 0.068305 at epoch 6. Model saved at /content/drive/MyDrive/face_landmark_234241.pt\n",
            "\n",
            "Epoch: 7 - Train Loss: 0.067141, Valid Loss: 0.065429, Elapsed time: 198s\n",
            "New minimum validation loss of 0.065429 at epoch 7. Model saved at /content/drive/MyDrive/face_landmark_234241.pt\n",
            "\n",
            "Epoch: 8 - Train Loss: 0.066737, Valid Loss: 0.067472, Elapsed time: 198s\n",
            "\n",
            "Epoch: 9 - Train Loss: 0.065129, Valid Loss: 0.063074, Elapsed time: 199s\n",
            "New minimum validation loss of 0.063074 at epoch 9. Model saved at /content/drive/MyDrive/face_landmark_234241.pt\n",
            "\n",
            "Epoch: 10 - Train Loss: 0.062981, Valid Loss: 0.066690, Elapsed time: 197s\n",
            "\n",
            "Epoch: 11 - Train Loss: 0.063645, Valid Loss: 0.065401, Elapsed time: 198s\n",
            "\n",
            "Epoch: 12 - Train Loss: 0.062989, Valid Loss: 0.068443, Elapsed time: 198s\n",
            "\n",
            "Epoch: 13 - Train Loss: 0.062087, Valid Loss: 0.063199, Elapsed time: 198s\n",
            "\n",
            "Epoch: 14 - Train Loss: 0.062382, Valid Loss: 0.063823, Elapsed time: 199s\n",
            "\n",
            "Epoch: 15 - Train Loss: 0.062332, Valid Loss: 0.060860, Elapsed time: 199s\n",
            "New minimum validation loss of 0.060860 at epoch 15. Model saved at /content/drive/MyDrive/face_landmark_234241.pt\n",
            "\n",
            "Epoch: 16 - Train Loss: 0.061725, Valid Loss: 0.061427, Elapsed time: 199s\n",
            "\n",
            "Epoch: 17 - Train Loss: 0.061526, Valid Loss: 0.060312, Elapsed time: 199s\n",
            "New minimum validation loss of 0.060312 at epoch 17. Model saved at /content/drive/MyDrive/face_landmark_234241.pt\n",
            "\n",
            "Epoch: 18 - Train Loss: 0.061743, Valid Loss: 0.068240, Elapsed time: 197s\n",
            "\n",
            "Epoch: 19 - Train Loss: 0.062220, Valid Loss: 0.059302, Elapsed time: 199s\n",
            "New minimum validation loss of 0.059302 at epoch 19. Model saved at /content/drive/MyDrive/face_landmark_234241.pt\n",
            "\n",
            "Epoch: 20 - Train Loss: 0.062082, Valid Loss: 0.065215, Elapsed time: 199s\n",
            "\n",
            "Epoch: 21 - Train Loss: 0.052321, Valid Loss: 0.052645, Elapsed time: 198s\n",
            "New minimum validation loss of 0.052645 at epoch 21. Model saved at /content/drive/MyDrive/face_landmark_234241.pt\n",
            "\n",
            "Epoch: 22 - Train Loss: 0.051020, Valid Loss: 0.051630, Elapsed time: 202s\n",
            "New minimum validation loss of 0.051630 at epoch 22. Model saved at /content/drive/MyDrive/face_landmark_234241.pt\n",
            "\n",
            "Epoch: 23 - Train Loss: 0.050680, Valid Loss: 0.052509, Elapsed time: 202s\n",
            "\n",
            "Epoch: 24 - Train Loss: 0.050594, Valid Loss: 0.051577, Elapsed time: 202s\n",
            "New minimum validation loss of 0.051577 at epoch 24. Model saved at /content/drive/MyDrive/face_landmark_234241.pt\n",
            "\n",
            "Epoch: 25 - Train Loss: 0.050691, Valid Loss: 0.051797, Elapsed time: 201s\n",
            "\n",
            "Epoch: 26 - Train Loss: 0.050953, Valid Loss: 0.052022, Elapsed time: 199s\n",
            "\n",
            "Epoch: 27 - Train Loss: 0.051162, Valid Loss: 0.051640, Elapsed time: 199s\n",
            "\n",
            "Epoch: 28 - Train Loss: 0.051024, Valid Loss: 0.051560, Elapsed time: 198s\n",
            "New minimum validation loss of 0.051560 at epoch 28. Model saved at /content/drive/MyDrive/face_landmark_234241.pt\n",
            "\n",
            "Epoch: 29 - Train Loss: 0.050741, Valid Loss: 0.051453, Elapsed time: 198s\n",
            "New minimum validation loss of 0.051453 at epoch 29. Model saved at /content/drive/MyDrive/face_landmark_234241.pt\n",
            "\n",
            "Epoch: 30 - Train Loss: 0.050767, Valid Loss: 0.052318, Elapsed time: 198s\n",
            "\n",
            "Epoch: 31 - Train Loss: 0.050661, Valid Loss: 0.052004, Elapsed time: 199s\n",
            "\n",
            "Epoch: 32 - Train Loss: 0.051212, Valid Loss: 0.052000, Elapsed time: 199s\n",
            "\n",
            "Epoch: 33 - Train Loss: 0.051118, Valid Loss: 0.052227, Elapsed time: 197s\n",
            "\n",
            "Epoch: 34 - Train Loss: 0.050767, Valid Loss: 0.052175, Elapsed time: 198s\n",
            "\n",
            "Epoch: 35 - Train Loss: 0.050733, Valid Loss: 0.052764, Elapsed time: 197s\n",
            "\n",
            "Epoch: 36 - Train Loss: 0.050695, Valid Loss: 0.051816, Elapsed time: 197s\n",
            "\n",
            "Epoch: 37 - Train Loss: 0.050886, Valid Loss: 0.052056, Elapsed time: 196s\n",
            "\n",
            "Epoch: 38 - Train Loss: 0.051017, Valid Loss: 0.051903, Elapsed time: 196s\n",
            "\n",
            "Epoch: 39 - Train Loss: 0.050704, Valid Loss: 0.050877, Elapsed time: 196s\n",
            "New minimum validation loss of 0.050877 at epoch 39. Model saved at /content/drive/MyDrive/face_landmark_234241.pt\n",
            "\n",
            "Epoch: 40 - Train Loss: 0.050670, Valid Loss: 0.051769, Elapsed time: 196s\n",
            "\n",
            "Epoch: 41 - Train Loss: 0.049316, Valid Loss: 0.050755, Elapsed time: 197s\n",
            "New minimum validation loss of 0.050755 at epoch 41. Model saved at /content/drive/MyDrive/face_landmark_234241.pt\n",
            "\n",
            "Epoch: 42 - Train Loss: 0.049366, Valid Loss: 0.050232, Elapsed time: 199s\n",
            "New minimum validation loss of 0.050232 at epoch 42. Model saved at /content/drive/MyDrive/face_landmark_234241.pt\n",
            "\n",
            "Epoch: 43 - Train Loss: 0.049272, Valid Loss: 0.050721, Elapsed time: 200s\n",
            "\n",
            "Epoch: 44 - Train Loss: 0.048972, Valid Loss: 0.051157, Elapsed time: 200s\n",
            "\n",
            "Epoch: 45 - Train Loss: 0.049130, Valid Loss: 0.050457, Elapsed time: 201s\n",
            "\n",
            "Epoch: 46 - Train Loss: 0.049270, Valid Loss: 0.051012, Elapsed time: 201s\n",
            "\n",
            "Epoch: 47 - Train Loss: 0.049201, Valid Loss: 0.050266, Elapsed time: 200s\n",
            "\n",
            "Epoch: 48 - Train Loss: 0.049262, Valid Loss: 0.051039, Elapsed time: 201s\n",
            "\n",
            "Epoch: 49 - Train Loss: 0.048947, Valid Loss: 0.051248, Elapsed time: 199s\n",
            "\n",
            "Epoch: 50 - Train Loss: 0.049083, Valid Loss: 0.051235, Elapsed time: 199s\n",
            "Training complete!\n"
          ]
        }
      ],
      "source": [
        "# Define the model\n",
        "model = ResNet18Finetune()\n",
        "model.cuda()  # Move model to GPU\n",
        "\n",
        "# Loss function, optimizer, and scheduler\n",
        "criterion = nn.L1Loss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Learning rate set to 0.001\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
        "\n",
        "# Initialize minimum loss to infinity\n",
        "loss_min = float('inf')\n",
        "\n",
        "# Define number of epochs for training\n",
        "num_epochs = 50\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    start = time.time()\n",
        "    # Initialize training and validation loss counters\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "\n",
        "    # Set model to training mode\n",
        "    model.train()\n",
        "\n",
        "    # Iterate through training data\n",
        "    for step, (images, landmarks) in enumerate(train_loader, start=1):\n",
        "        # Move images and landmarks to GPU\n",
        "        images, landmarks = images.cuda(), landmarks.view(landmarks.size(0), 68, 2).cuda()\n",
        "\n",
        "        # Zero the optimizer gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        predictions = model(images)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(predictions, landmarks)\n",
        "\n",
        "        # Backward pass and optimization step\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Accumulate training loss\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    # Calculate average training loss for the epoch\n",
        "    avg_train_loss = train_loss / len(train_loader)\n",
        "\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Iterate through validation data\n",
        "    with torch.no_grad():\n",
        "        for step, (images, landmarks) in enumerate(valid_loader, start=1):\n",
        "            # Move images and landmarks to GPU\n",
        "            images, landmarks = images.cuda(), landmarks.view(landmarks.size(0), 68, 2).cuda()\n",
        "\n",
        "            # Forward pass\n",
        "            predictions = model(images)\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = criterion(predictions, landmarks)\n",
        "\n",
        "            # Accumulate validation loss\n",
        "            valid_loss += loss.item()\n",
        "\n",
        "    # Calculate average validation loss for the epoch\n",
        "    avg_valid_loss = valid_loss / len(valid_loader)\n",
        "\n",
        "    # Log the average training and validation loss for each epoch\n",
        "    print(f\"\\nEpoch: {epoch} - Train Loss: {avg_train_loss:.6f}, Valid Loss: {avg_valid_loss:.6f}, Elapsed time: {int(time.time() - start)}s\")\n",
        "\n",
        "    # Save the model if validation loss decreases\n",
        "    if avg_valid_loss < loss_min:\n",
        "        loss_min = avg_valid_loss\n",
        "        model_path = '/content/drive/MyDrive/face_landmark_234241.pt'  # Specify the model save path\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "        print(f\"New minimum validation loss of {loss_min:.6f} at epoch {epoch}. Model saved at {model_path}\")\n",
        "\n",
        "    # Step the learning rate scheduler\n",
        "    scheduler.step()\n",
        "print(\"Training complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Continue to finetune"
      ],
      "metadata": {
        "id": "6mLCMvxVv_fg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet18Finetune()\n",
        "pretrained_model = '/content/drive/MyDrive/face_landmark_28424_6.pt'\n",
        "model.load_state_dict(torch.load(pretrained_model))\n",
        "\n",
        "model.cuda()\n",
        "criterion = nn.L1Loss()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size = 10, gamma = 0.1)\n",
        "\n",
        "loss_min = np.inf\n",
        "num_epochs = 100\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "  start_time = time.time()\n",
        "  loss_train = 0\n",
        "  loss_valid = 0\n",
        "  running_loss = 0\n",
        "\n",
        "  model.train()\n",
        "  train_loader_iteration = iter(train_loader)\n",
        "  for step in range(len(train_loader)):\n",
        "    images, landmarks = next(train_loader_iteration)\n",
        "    images, landmarks = images.cuda(), landmarks.view(landmarks.size(0), 68, 2).cuda()\n",
        "\n",
        "    predictions = model(images)\n",
        "    #optimizer\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    #find the loss for current step\n",
        "    loss_train_step = criterion(predictions, landmarks)\n",
        "\n",
        "    #calculate the gradient\n",
        "    loss_train_step.backward()\n",
        "\n",
        "    #update the parameter\n",
        "    optimizer.step()\n",
        "\n",
        "    loss_train += loss_train_step.item()\n",
        "\n",
        "  avg_train_loss = loss_train / len(train_loader)\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for (images, landmarks) in valid_loader:\n",
        "      images = images.cuda()\n",
        "      landmarks = landmarks.view(landmarks.size(0),68, 2).cuda()\n",
        "\n",
        "      predictions = model(images)\n",
        "\n",
        "      # find the loss for the current step\n",
        "      loss_valid_step = criterion(predictions, landmarks)\n",
        "\n",
        "      loss_valid += loss_valid_step.item()\n",
        "\n",
        "\n",
        "  avg_valid_loss = loss_valid/ len(valid_loader)\n",
        "  # Log the average training and validation loss for each epoch\n",
        "  print(f\"\\nEpoch: {epoch} - Train Loss: {avg_train_loss:.6f}, Valid Loss: {avg_valid_loss:.6f}, Elapsed time: {int(time.time() - start_time)}s\")\n",
        "\n",
        "  # Save the model if validation loss decreases\n",
        "  if avg_valid_loss < loss_min:\n",
        "      loss_min = avg_valid_loss\n",
        "      model_path = '/content/drive/MyDrive/face_landmark_28424_7.pt'  # Specify the model save path\n",
        "      torch.save(model.state_dict(), model_path)\n",
        "      print(f\"New minimum validation loss of {loss_min:.6f} at epoch {epoch}. Model saved at {model_path}\")\n",
        "\n",
        "  # Step the learning rate scheduler\n",
        "  scheduler.step()\n",
        "print(\"Training complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bJHPtpawCIw",
        "outputId": "b226917d-9e25-429b-d7d1-8b9f725db848"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 152MB/s]\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 1 - Train Loss: 0.011557, Valid Loss: 0.010725, Elapsed time: 216s\n",
            "New minimum validation loss of 0.010725 at epoch 1. Model saved at /content/drive/MyDrive/face_landmark_28424_7.pt\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2 - Train Loss: 0.011416, Valid Loss: 0.010445, Elapsed time: 221s\n",
            "New minimum validation loss of 0.010445 at epoch 2. Model saved at /content/drive/MyDrive/face_landmark_28424_7.pt\n",
            "\n",
            "Epoch: 3 - Train Loss: 0.011116, Valid Loss: 0.010540, Elapsed time: 219s\n",
            "\n",
            "Epoch: 4 - Train Loss: 0.011015, Valid Loss: 0.010927, Elapsed time: 219s\n",
            "\n",
            "Epoch: 5 - Train Loss: 0.010915, Valid Loss: 0.010819, Elapsed time: 218s\n",
            "\n",
            "Epoch: 6 - Train Loss: 0.010831, Valid Loss: 0.011122, Elapsed time: 216s\n",
            "\n",
            "Epoch: 7 - Train Loss: 0.010764, Valid Loss: 0.011084, Elapsed time: 220s\n",
            "\n",
            "Epoch: 8 - Train Loss: 0.010653, Valid Loss: 0.010924, Elapsed time: 218s\n",
            "\n",
            "Epoch: 9 - Train Loss: 0.010635, Valid Loss: 0.011732, Elapsed time: 217s\n",
            "\n",
            "Epoch: 10 - Train Loss: 0.010657, Valid Loss: 0.010960, Elapsed time: 219s\n",
            "\n",
            "Epoch: 11 - Train Loss: 0.009344, Valid Loss: 0.010170, Elapsed time: 219s\n",
            "New minimum validation loss of 0.010170 at epoch 11. Model saved at /content/drive/MyDrive/face_landmark_28424_7.pt\n",
            "\n",
            "Epoch: 12 - Train Loss: 0.008973, Valid Loss: 0.010031, Elapsed time: 218s\n",
            "New minimum validation loss of 0.010031 at epoch 12. Model saved at /content/drive/MyDrive/face_landmark_28424_7.pt\n",
            "\n",
            "Epoch: 13 - Train Loss: 0.008874, Valid Loss: 0.009890, Elapsed time: 218s\n",
            "New minimum validation loss of 0.009890 at epoch 13. Model saved at /content/drive/MyDrive/face_landmark_28424_7.pt\n",
            "\n",
            "Epoch: 14 - Train Loss: 0.008740, Valid Loss: 0.009969, Elapsed time: 218s\n",
            "\n",
            "Epoch: 15 - Train Loss: 0.008682, Valid Loss: 0.009889, Elapsed time: 220s\n",
            "New minimum validation loss of 0.009889 at epoch 15. Model saved at /content/drive/MyDrive/face_landmark_28424_7.pt\n",
            "\n",
            "Epoch: 16 - Train Loss: 0.008524, Valid Loss: 0.009936, Elapsed time: 219s\n",
            "\n",
            "Epoch: 17 - Train Loss: 0.008483, Valid Loss: 0.009957, Elapsed time: 219s\n",
            "\n",
            "Epoch: 18 - Train Loss: 0.008403, Valid Loss: 0.009861, Elapsed time: 220s\n",
            "New minimum validation loss of 0.009861 at epoch 18. Model saved at /content/drive/MyDrive/face_landmark_28424_7.pt\n",
            "\n",
            "Epoch: 19 - Train Loss: 0.008387, Valid Loss: 0.009923, Elapsed time: 218s\n",
            "\n",
            "Epoch: 20 - Train Loss: 0.008331, Valid Loss: 0.009857, Elapsed time: 217s\n",
            "New minimum validation loss of 0.009857 at epoch 20. Model saved at /content/drive/MyDrive/face_landmark_28424_7.pt\n",
            "\n",
            "Epoch: 21 - Train Loss: 0.008170, Valid Loss: 0.009750, Elapsed time: 219s\n",
            "New minimum validation loss of 0.009750 at epoch 21. Model saved at /content/drive/MyDrive/face_landmark_28424_7.pt\n",
            "\n",
            "Epoch: 22 - Train Loss: 0.008131, Valid Loss: 0.009820, Elapsed time: 217s\n",
            "\n",
            "Epoch: 23 - Train Loss: 0.008084, Valid Loss: 0.009921, Elapsed time: 217s\n",
            "\n",
            "Epoch: 24 - Train Loss: 0.008113, Valid Loss: 0.009735, Elapsed time: 217s\n",
            "New minimum validation loss of 0.009735 at epoch 24. Model saved at /content/drive/MyDrive/face_landmark_28424_7.pt\n",
            "\n",
            "Epoch: 25 - Train Loss: 0.008071, Valid Loss: 0.009828, Elapsed time: 218s\n",
            "\n",
            "Epoch: 26 - Train Loss: 0.008082, Valid Loss: 0.009874, Elapsed time: 218s\n",
            "\n",
            "Epoch: 27 - Train Loss: 0.008074, Valid Loss: 0.009756, Elapsed time: 216s\n",
            "\n",
            "Epoch: 28 - Train Loss: 0.008078, Valid Loss: 0.009754, Elapsed time: 219s\n",
            "\n",
            "Epoch: 29 - Train Loss: 0.008079, Valid Loss: 0.009736, Elapsed time: 219s\n",
            "\n",
            "Epoch: 30 - Train Loss: 0.008049, Valid Loss: 0.009800, Elapsed time: 218s\n",
            "\n",
            "Epoch: 31 - Train Loss: 0.008061, Valid Loss: 0.009722, Elapsed time: 221s\n",
            "New minimum validation loss of 0.009722 at epoch 31. Model saved at /content/drive/MyDrive/face_landmark_28424_7.pt\n",
            "\n",
            "Epoch: 32 - Train Loss: 0.008036, Valid Loss: 0.009734, Elapsed time: 221s\n",
            "\n",
            "Epoch: 33 - Train Loss: 0.008063, Valid Loss: 0.009781, Elapsed time: 226s\n",
            "\n",
            "Epoch: 34 - Train Loss: 0.008035, Valid Loss: 0.009764, Elapsed time: 221s\n",
            "\n",
            "Epoch: 35 - Train Loss: 0.008010, Valid Loss: 0.009722, Elapsed time: 223s\n",
            "New minimum validation loss of 0.009722 at epoch 35. Model saved at /content/drive/MyDrive/face_landmark_28424_7.pt\n",
            "\n",
            "Epoch: 36 - Train Loss: 0.008063, Valid Loss: 0.009891, Elapsed time: 222s\n",
            "\n",
            "Epoch: 37 - Train Loss: 0.008009, Valid Loss: 0.009779, Elapsed time: 220s\n",
            "\n",
            "Epoch: 38 - Train Loss: 0.008052, Valid Loss: 0.009736, Elapsed time: 222s\n",
            "\n",
            "Epoch: 39 - Train Loss: 0.008067, Valid Loss: 0.009758, Elapsed time: 222s\n",
            "\n",
            "Epoch: 40 - Train Loss: 0.008051, Valid Loss: 0.009725, Elapsed time: 220s\n",
            "\n",
            "Epoch: 41 - Train Loss: 0.008043, Valid Loss: 0.009780, Elapsed time: 220s\n",
            "\n",
            "Epoch: 42 - Train Loss: 0.008011, Valid Loss: 0.009744, Elapsed time: 220s\n",
            "\n",
            "Epoch: 43 - Train Loss: 0.008014, Valid Loss: 0.009788, Elapsed time: 220s\n",
            "\n",
            "Epoch: 44 - Train Loss: 0.008014, Valid Loss: 0.009841, Elapsed time: 221s\n",
            "\n",
            "Epoch: 45 - Train Loss: 0.008007, Valid Loss: 0.009699, Elapsed time: 218s\n",
            "New minimum validation loss of 0.009699 at epoch 45. Model saved at /content/drive/MyDrive/face_landmark_28424_7.pt\n",
            "\n",
            "Epoch: 46 - Train Loss: 0.008071, Valid Loss: 0.009772, Elapsed time: 217s\n",
            "\n",
            "Epoch: 47 - Train Loss: 0.008042, Valid Loss: 0.009804, Elapsed time: 216s\n",
            "\n",
            "Epoch: 48 - Train Loss: 0.008011, Valid Loss: 0.009790, Elapsed time: 218s\n",
            "\n",
            "Epoch: 49 - Train Loss: 0.008014, Valid Loss: 0.009816, Elapsed time: 219s\n",
            "\n",
            "Epoch: 50 - Train Loss: 0.008025, Valid Loss: 0.009745, Elapsed time: 207s\n",
            "\n",
            "Epoch: 51 - Train Loss: 0.007978, Valid Loss: 0.009760, Elapsed time: 215s\n",
            "\n",
            "Epoch: 52 - Train Loss: 0.008026, Valid Loss: 0.009851, Elapsed time: 215s\n",
            "\n",
            "Epoch: 53 - Train Loss: 0.008022, Valid Loss: 0.009895, Elapsed time: 220s\n",
            "\n",
            "Epoch: 54 - Train Loss: 0.008025, Valid Loss: 0.009685, Elapsed time: 223s\n",
            "New minimum validation loss of 0.009685 at epoch 54. Model saved at /content/drive/MyDrive/face_landmark_28424_7.pt\n",
            "\n",
            "Epoch: 55 - Train Loss: 0.008041, Valid Loss: 0.009758, Elapsed time: 220s\n",
            "\n",
            "Epoch: 56 - Train Loss: 0.008047, Valid Loss: 0.009720, Elapsed time: 220s\n",
            "\n",
            "Epoch: 57 - Train Loss: 0.007998, Valid Loss: 0.009839, Elapsed time: 221s\n",
            "\n",
            "Epoch: 58 - Train Loss: 0.008012, Valid Loss: 0.009700, Elapsed time: 218s\n",
            "\n",
            "Epoch: 59 - Train Loss: 0.008025, Valid Loss: 0.009812, Elapsed time: 219s\n",
            "\n",
            "Epoch: 60 - Train Loss: 0.008008, Valid Loss: 0.009831, Elapsed time: 221s\n",
            "\n",
            "Epoch: 61 - Train Loss: 0.008082, Valid Loss: 0.009806, Elapsed time: 218s\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}